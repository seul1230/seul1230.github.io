---
layout: post
title:  "ë¹…ë°ì´í„° | íŠ¹ì„± ì„ íƒ Feature Selection"
date:   2024-05-23 14:30:09 +0900
style: border
color: info
description: <strong>[ ê³µë¶€ & ì •ë¦¬ ]</strong><br/>Feature Selection - Filter / Wrapper / Embedded
# categories: tips
tags: [AI/ML/DL]
---
# [ ë¹…ë°ì´í„° ] íŠ¹ì„± ì„ íƒ Feature Selection - Filter / Wrapper / Embedded

feature ë¥¼ ì¤„ì´ëŠ” ë°©ë²• ì¤‘ Feature Selectionì— ëŒ€í•´ ì•Œì•„ë³´ì. ê¸°ì¡´ ë°ì´í„°ì˜ featureë“¤ì˜ ê²°í•© ë³€ìˆ˜ë¥¼ ë§Œë“¤ì–´ì„œ ë°ì´í„° ì°¨ì›ì„ ì¶•ì†Œí•˜ëŠ” <code>Extraction</code> ê³¼ ë‹¬ë¦¬, <code>Selection</code> ì€ target ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ feature ë§Œì„ ì„ ì •í•˜ì—¬ feature ìˆ˜ë¥¼ ì¤„ì´ëŠ” ë°©ë²•ì´ë‹¤. ì§€ë‚œ í¬ìŠ¤íŠ¸ì— Feature Selection ì˜ Filter / Wrapper / Embedded Method ë¥¼ ì°¨ì›ì˜ ì €ì£¼ë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë°©ë²•ìœ¼ë¡œ ì–¸ê¸‰í–ˆì—ˆë‹¤.

> ì§€ë‚œ í¬ìŠ¤íŠ¸ : [[ ë¹…ë°ì´í„° ] ì°¨ì›ì˜ ì €ì£¼ (The curse of dimensionality) ë€?](https://seul1230.github.io/blog/curse-of-dimensionality)


<br/>


### íŠ¹ì„± ì„ íƒ Feature Selection ì´ë€?

> target ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ feature ë§Œì„ ì„ ì •í•˜ì—¬ feature ìˆ˜ë¥¼ ì¤„ì´ëŠ” ë°©ë²•

ëª¨ë¸ë§í•  ë•Œ ë°ì´í„°ì˜ ëª¨ë“  feature ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë©”ëª¨ë¦¬ ì¸¡ë©´ì—ì„œ ë§¤ìš° ë¹„íš¨ìœ¨ì ì´ê¸° ë•Œë¬¸ì— í•„ìš”í•œ feature ë§Œ ì„ íƒí•´ì„œ ì‚¬ìš©í•˜ê³ ì í•œ ë°©ë²•ì´ë‹¤.


â­ï¸â­ï¸ ì´ë¡œ ì¸í•œ íš¨ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
- í•™ìŠµ ì‹œê°„ ë‹¨ì¶•
- ëª¨ë¸ ë‹¨ìˆœí™”
- ì°¨ì›ì˜ ì €ì£¼ ë° ê³¼ì í•© Over-fitting ë°©ì§€

<br/>


### Methods

Feature Selection ì€ í¬ê²Œ Filter, Wrapper, Embedded 3ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ë¶„ë¥˜ëœë‹¤.

- <code>Filter Method</code> : feature ê°„ ìƒê´€ê´€ê³„ íŒŒì•…
- <code>Wrapper Method</code> : Feature Subsetì˜ ìœ ìš©ì„±ì„ ì¸¡ì •
- <code>Embedded Method</code> : Feature Subsetì˜ ìœ ìš©ì„±ì„ ì¸¡ì •í•˜ì§€ë§Œ, ë‚´ì¥ metricì„ ì‚¬ìš©

<br/>

#### 1ï¸âƒ£ Filter Method

í†µê³„ì  ì¸¡ì • ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ feature ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•œ ë’¤, ë†’ì€ ìƒê´€ê³„ìˆ˜ë¥¼ ê°€ì§€ëŠ” featureë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì´ë‹¤.

- ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•
- ê³„ì‚°ì†ë„ê°€ ë¹ ë¥´ê³  ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ì•Œì•„ë‚´ëŠ” ë° ì í•© -> Wrapper ê¸°ë²• ì´ì „ ì „ì²˜ë¦¬ì— ì‚¬ìš©ëœë‹¤.
- ìƒê´€ê³„ìˆ˜ê°€ ë†’ì€ featureë¼ê³  í•´ì„œ ëª¨ë¸ì— ì í•©í•œ featureì¸ ê²ƒë§Œì€ ì•„ë‹ˆë‹¤.

<br/>

<p class='line-mark-blue'><strong>ğŸ’¡ ë°©ë²•ë¡  ì¢…ë¥˜</strong></p>
- <font color='#004080'><strong>ìƒê´€ê³„ìˆ˜ Correlation Coefficient</strong></font>
  - ë‘ ë³€ìˆ˜ ì‚¬ì´ì˜ í†µê³„ì© ê´€ê³„ë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•´ íŠ¹ì •í•œ ìƒê´€ê´€ê³„ì˜ ì •ë„ë¥¼ ë‚˜íƒ€ë‚¸ ìˆ˜ì¹˜
  - ```df.corr()```
- <font color='#004080'><strong>ì¹´ì´ì œê³± ê²€ì • Chi-square Test</strong></font>
  - ì¹´ì´ì œê³± ë¶„í¬ì— ê¸°ì´ˆí•œ í†µê³„ì  ë°©ë²•
  - ê´€ì°°ëœ ë¹ˆë„ê°€ ê¸°ëŒ€ë˜ëŠ” ë¹ˆë„ì™€ ì˜ë¯¸ìˆê²Œ ë‹¤ë¥¸ì§€ ì—¬ë¶€ë¥¼ ê²€ì¦
- <font color='#004080'><strong>í”¼ì…” ìŠ¤ì½”ì–´ Fisher Score</strong></font>
  - ìµœëŒ€ê°€ëŠ¥ë„ ë°©ì •ì‹ Maximum Likelihood Function ì„ í’€ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•
- <font color='#004080'><strong>ë¶„ì‚° ê¸°ë°˜ ì„ íƒ Variance Threshold</strong></font>
  - ë¶„ì‚°ì´ ë‚®ì€ ë³€ìˆ˜ë¥¼ ì œê±°í•˜ëŠ” ë°©ë²•
  -  ë‹¤ì–‘í•œ í‘œë³¸ì— ë”°ë¼ ê·¸ë‹¤ì§€ ë³€í™”ê°€ ì—†ëŠ” featureëŠ” ì˜ˆì¸¡ì— ë³„ ë„ì›€ì´ ë˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.
- <font color='#004080'><strong>ì •ë³´ ì†Œë“ Information Gain</strong></font>
  - ê°€ì¥ ì •ë³´ ì†Œë“ì´ ë†’ì€ ì†ì„±ì„ ì„ íƒí•˜ëŠ” ë°©ë²•
  - ì–´ë–¤ feature ë¥¼ ì„ íƒí•¨ìœ¼ë¡œì¨ ë°ì´í„°ë¥¼ ë” ì˜ êµ¬ë¶„í•˜ê²Œ ëœë‹¤.
  - IGê°€ í´ìˆ˜ë¡ ë³€ë³„ë ¥ì´ ì¢‹ë‹¤.

<br/>

#### 2ï¸âƒ£ Wrapper Method

ì˜ˆì¸¡ ì •í™•ë„ì—ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” feature subset ì„ ì„ íƒí•˜ëŠ” ê¸°ë²•ì´ë‹¤.

- ì¼ë°˜ì ìœ¼ë¡œ Filter Method ë³´ë‹¤ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ë‹¤.
- feature ì˜ ì¡°í•©ì„ ì •í•˜ì—¬ ê¸°ê³„í•™ìŠµì„ ì§„í–‰í•œ ë’¤, Inference ê¹Œì§€ì˜ ì¼ë ¨ì˜ ê³¼ì •ì„ feature ì¡°í•©ì„ ë°”ê¿”ê°€ë©´ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ì¡°í•©ì„ ì°¾ì•„ë‚¸ë‹¤.
- ë°˜ë³µì ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰ -> ë§ì€ ì‹œê°„ì„ ì†Œìš”, ë¶€ë¶„ì§‘í•© ìˆ˜ ê¸°í•˜ê¸‰ìˆ˜ì  ì¦ê°€ -> ê³¼ì í•© ìœ„í—˜

<br/>

<p class='line-mark-blue'><strong>ğŸ’¡ ë°©ë²•ë¡  ì¢…ë£Œ</strong></p>
- <font color='#004080'><strong>Forward Selection</strong></font>
  - feature ê°€ ì—†ëŠ” ìƒíƒœë¡œ ì‹œì‘í•´ì„œ ì„±ëŠ¥ì„ ê°€ì¥ ë§ì´ í–¥ìƒì‹œí‚¤ëŠ” featureë¥¼ í•˜ë‚˜ì”© ì¶”ê°€í•˜ëŠ” ë°©ë²•
  - ë” ì´ìƒ ì„±ëŠ¥ í–¥ìƒì´ ì—†ì„ ë•Œê¹Œì§€ feature ì¶”ê°€
- <font color='#004080'><strong>Backward Elimination</strong></font>
  - ëª¨ë“  feature ë¥¼ ê°€ì§€ê³  ì‹œì‘í•´ì„œ ê°€ì¥ ì˜í–¥ì„ ì ê²Œ ì£¼ëŠ” featureë¥¼ í•˜ë‚˜ì”© ì œê±°í•˜ëŠ” ë°©ë²•
  - ë” ì´ìƒ ì„±ëŠ¥ í–¥ìƒì´ ì—†ì„ ë•Œê¹Œì§€ feature ì œê±°
- <font color='#004080'><strong>Stepwise Method</strong></font>
  - Forward Selection ê³¼ Backward Elimination ì„ ê²°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
  - ëª¨ë“  feature ë¥¼ ê°€ì§€ê³  ì‹œì‘í•´ì„œ ìµœì•…ì˜ feature ì œê±°, ëª¨ë¸ì—ì„œ ë¹ ì ¸ìˆëŠ” feature ì¤‘ ìµœìƒì˜ feature ì¶”ê°€í•˜ëŠ” ë°©ë²•
  - ë°˜ëŒ€ë¡œ feature ê°€ ì—†ëŠ” ìƒíƒœì—ì„œ ì‹œì‘í•˜ì—¬ feature ì¶”ê°€, ì‚­ì œë¥¼ ë°˜ë³µí•  ìˆ˜ë„ ìˆìŒ


<br/>

#### 3ï¸âƒ£ Embedded Method

ì•ì„œ ì–¸ê¸‰ëœ Filter ì™€ Wrapper method ì˜ ì¥ì ì„ ê²°í•©í•œ ë°©ë²•ì´ë‹¤.

- Feature selection ê¸°ëŠ¥ì´ ìì²´ì ìœ¼ë¡œ ì¶”ê°€ë˜ì–´ ìˆëŠ” ëª¨ë¸ì„ ì‚¬ìš©
  - Lasso, Ridge, Decision Tree ë“±ì˜ ì•Œê³ ë¦¬ì¦˜ì€ ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ ìì²´ì—ì„œ feature selection ìˆ˜í–‰
- ê°ê°ì˜ feature ë¥¼ ì§ì ‘ í•™ìŠµí•˜ì—¬ ëª¨ë¸ì˜ ì •í™•ë„ì— ê¸°ì—¬í•˜ëŠ” feature ì„ íƒ

<br/>

<p class='line-mark-blue'><strong>ğŸ’¡ ë°©ë²•ë¡  ì¢…ë¥˜</strong></p>
- <font color='#004080'><strong>Lasso Regression</strong></font>
  - L1 ì •ê·œí™”ë¥¼ í†µí•´ ì œì•½ì„ ì£¼ëŠ” ë°©ë²•
- <font color='#004080'><strong>Ridge Regression</strong></font>
  - L2 ì •ê·œí™”ë¥¼ í†µí•´ ì œì•½ì„ ì£¼ëŠ” ë°©ë²•
- <font color='#004080'><strong>Select From Model</strong></font>
  - Decision Tree ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì—ì„œ feature ë½‘ì•„ì˜¤ëŠ” ë°©ë²•
- <font color='#004080'><strong>Elastic Net</strong></font>
  - Lasso Regression ê³¼ Ridge Regression ì˜ í˜ë„í‹°ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë°©ë²•
  - í˜ë„í‹°ëŠ” Lassoì˜ í¬ì†Œì„±ê³¼ Ridge íšŒê·€ì˜ ë¶€ë“œëŸ¬ì›€ ì‚¬ì´ ê· í˜•ì„ ì œê³µ



<br/>




## Reference

- [[ML] Feature Selection (Filter Method & Wrapper Method & Embedded Method)](https://wooono.tistory.com/249)
- [[PP] Data Reduction(2)_Feature Selection(íŠ¹ì„± ì„ íƒ)](https://velog.io/@seungwoong12/selection)

<br><br><br>


