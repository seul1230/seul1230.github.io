---
layout: post
title:  "TIL | PCA"
date:   2022-11-21 13:00:09 +0900
categories: SpecialLecture
description: ë¨¸ì‹ ëŸ¬ë‹ - PCA (Principal Component Analysis) <br/><br/>ğŸ‘©ğŸ»â€ğŸ’» K-MOOC ì‹¤ìŠµìœ¼ë¡œ ë°°ìš°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê°•ì˜
tags: [TIL]
---
# [ AI / ML ] ë¨¸ì‹ ëŸ¬ë‹ - PCA (Principal Component Analysis) 
#### ğŸ‘©ğŸ»â€ğŸ’» K-MOOC ì‹¤ìŠµìœ¼ë¡œ ë°°ìš°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê°•ì˜
ğŸ“™ í•´ë‹¹ í¬ìŠ¤íŠ¸ëŠ” [K-MOOC ê°•ì˜](http://www.kmooc.kr/courses/course-v1:SSUk+SSMOOC20K+2022_T1/course/) ë‚´ìš©ê³¼ ì¶”ê°€ë¡œ ë‹¤ë¥¸ ìë£Œë“¤ì„ ì°¾ì•„ ë‚´ìš©ì„ ì‘ì„±í•˜ì˜€ìœ¼ë©°, **ì´ë¡  ë° ê°œë…**ì— ëŒ€í•´ ê³µë¶€í•˜ê³  **ì˜ˆì œ ì‹¤ìŠµ**ë„ ì§„í–‰í•œ í›„ ë‚´ìš©ì„ ì •ë¦¬í•˜ì˜€ë‹¤.

**[[ AI ] ì¸ê³µì§€ëŠ¥ê³¼ ë¨¸ì‹ ëŸ¬ë‹, ê·¸ë¦¬ê³  ë”¥ëŸ¬ë‹](https://seul1230.github.io/speciallecture/2022-11-21-likelion-TIL1/)**ì™€ ê°™ì€ ë‚  ì‘ì„±ëœ í¬ìŠ¤íŠ¸ì´ë‹¤. 

<br/>


***

## ëª©ì°¨
- [\[ AI / ML \] ë¨¸ì‹ ëŸ¬ë‹ - PCA (Principal Component Analysis)](#-ai--ml--ë¨¸ì‹ ëŸ¬ë‹---pca-principal-component-analysis)
      - [ğŸ‘©ğŸ»â€ğŸ’» K-MOOC ì‹¤ìŠµìœ¼ë¡œ ë°°ìš°ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ê°•ì˜](#-k-mooc-ì‹¤ìŠµìœ¼ë¡œ-ë°°ìš°ëŠ”-ë¨¸ì‹ ëŸ¬ë‹-ê°•ì˜)
  - [ëª©ì°¨](#ëª©ì°¨)
  - [1. ì£¼ì„±ë¶„ ë¶„ì„ Principal Component Analysis](#1-ì£¼ì„±ë¶„-ë¶„ì„-principal-component-analysis)
      - [ë”°ë¼ì„œ PCAëŠ” ì£¼ë¡œ](#ë”°ë¼ì„œ-pcaëŠ”-ì£¼ë¡œ)
  - [2. PCAì˜ ì›ë¦¬ How It Works](#2-pcaì˜-ì›ë¦¬-how-it-works)
  - [3. ë¶„ì‚°ì„ ìµœëŒ€ë¡œ ë³´ì¡´í•  ìˆ˜ ìˆëŠ” ì¶•ì„ ì„ íƒí•˜ëŠ” ì´ìœ ?](#3-ë¶„ì‚°ì„-ìµœëŒ€ë¡œ-ë³´ì¡´í• -ìˆ˜-ìˆëŠ”-ì¶•ì„-ì„ íƒí•˜ëŠ”-ì´ìœ )
  - [4. PCA ì ìš©](#4-pca-ì ìš©)
      - [Step 1 : ë°ì´í„° ì •ê·œí™” (ê° ë³€ìˆ˜ ê°’ë“¤ì˜ í‰ê·  = 0)](#step-1--ë°ì´í„°-ì •ê·œí™”-ê°-ë³€ìˆ˜-ê°’ë“¤ì˜-í‰ê· --0)
      - [Step 2 : ìµœì í™” ë¬¸ì œ ì •ì˜](#step-2--ìµœì í™”-ë¬¸ì œ-ì •ì˜)
      - [Step 3 : ìµœì í•´ ë„ì¶œ](#step-3--ìµœì í•´-ë„ì¶œ)
      - [Step 4 : ê³ ìœ ë²¡í„° (eigenvector) ë“¤ì„ ê³ ìœ ê°’ (eigenvalue) ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬](#step-4--ê³ ìœ ë²¡í„°-eigenvector-ë“¤ì„-ê³ ìœ ê°’-eigenvalue-ê¸°ì¤€ìœ¼ë¡œ-ë‚´ë¦¼ì°¨ìˆœ-ì •ë ¬)
      - [Step 5 : ë³€ìˆ˜ ì¶”ì¶œì„ í†µí•œ ë°ì´í„° ë³€í™˜](#step-5--ë³€ìˆ˜-ì¶”ì¶œì„-í†µí•œ-ë°ì´í„°-ë³€í™˜)
      - [Step 6 : ì¶”ì¶œëœ ë³€ìˆ˜ ì¤‘ ì¼ë¶€ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì—­ë³€í™˜](#step-6--ì¶”ì¶œëœ-ë³€ìˆ˜-ì¤‘-ì¼ë¶€ë§Œì„-ì‚¬ìš©í•˜ì—¬-ë°ì´í„°-ì—­ë³€í™˜)
  - [5. ê²°ê³¼ í™•ì¸](#5-ê²°ê³¼-í™•ì¸)
  - [ğŸ’» ì‹¤ìŠµ ì˜ˆì œ ì½”ë“œ](#-ì‹¤ìŠµ-ì˜ˆì œ-ì½”ë“œ)
  - [ë§ˆë¬´ë¦¬í•˜ë©´ì„œ..](#ë§ˆë¬´ë¦¬í•˜ë©´ì„œ)
    - [ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ ë§Œë‚˜ìš” ğŸ™Œ](#ë‹¤ìŒ-í¬ìŠ¤íŠ¸ì—ì„œ-ë§Œë‚˜ìš”-)
  - [ì°¸ê³ ](#ì°¸ê³ )

<br/>

***

## 1. ì£¼ì„±ë¶„ ë¶„ì„ <font color='lightgray'>Principal Component Analysis</font>

ì°¨ì›ì¶•ì†Œ(dimensionality reduction)ì™€ ë³€ìˆ˜ì¶”ì¶œ(feature extraction) ê¸°ë²•ìœ¼ë¡œ ë„ë¦¬ ì“°ì´ê³  ìˆëŠ” **<mark style='background-color: #fff5b1'>PCA (Principal Component Analysis)</mark>**ì€ ë¹„ì§€ë„í•™ìŠµ <font color = 'gray'>Unsupervised Learning</font>ì—ì„œ 
ìë£Œì— **ì¤‘ë³µëœ ì •ë³´ê°€ ë§ì„ ê²½ìš°**, ìë£Œê°€ ê°–ëŠ” ì°¨ì›ë³´ë‹¤ **ë” ì‘ì€ ìˆ˜ì˜ ì°¨ì›ìœ¼ë¡œë„** ìë£Œì— ë‚´ì¬í•œ ì •ë³´ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ëŠ” ì•„ì´ë””ì–´ì—ì„œ ì†Œê°œëœ ê°œë…ì´ë‹¤. 

![](/assets/img/img_221121/pca.png){: .center width="80%"} 

* **ì£¼ì„±ë¶„ì´ë€** 
  * ì „ì²´ ë°ì´í„° (ë…ë¦½ë³€ìˆ˜)ì˜ ë¶„ì‚°ì„ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” ì„±ë¶„
* **ë³€ìˆ˜ì˜ ê°œìˆ˜ = ì°¨ì›ì˜ ê°œìˆ˜** <br/>
  â†’ ì°¨ì›ì´ ì¦ê°€í• ìˆ˜ë¡ ë°ì´í„°ê°€ í‘œí˜„í•´ì•¼ í•˜ëŠ” ê³µê°„ì€ ë³µì¡í•´ì§„ë‹¤. <br/>



#### ë”°ë¼ì„œ PCAëŠ” ì£¼ë¡œ
* ë³€ìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ ê¸°ì¡´ ë³€ìˆ˜ë¥¼ ì¡°í•©í•´ ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ê°€ì§€ê³  ëª¨ë¸ë§ì„ í•˜ë ¤ê³  í•˜ê±°ë‚˜
* **íšŒê·€ ë¶„ì„**ê³¼ ê°™ì€ ì¢…ì†ê´€ê³„ ë¶„ì„ì„ í•  ë•Œ **ë‹¤ì¤‘ ê³µì‚°ì„± <font color='gray'>multicollinearity</font>**ì„ ì—†ì• ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.

## 2. PCAì˜ ì›ë¦¬ <font color='lightgray'>How It Works</font>

ë°ì´í„°ì˜ ì°¨ì›ì„ ì¶•ì†Œí•  ë•Œ ê¸°ì¡´ì˜ ì •ë³´ê°€ ìµœëŒ€í•œ ë³´ì¡´ë  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì¶•ì„ ì°¾ì•„ì•¼ í•œë‹¤. ì´ë ‡ê²Œ ì°¾ì€ ì¶•ì„ Principle Componentë¼ê³  í•˜ë©°, ì£¼ë¡œ ì¤„ì—¬ì„œ PCë¼ê³  ë¶€ë¥¸ë‹¤. <br/><br/>

![](/assets/img/img_221121/pca_pc.gif){: .center width="100%"} <br/>


PCë¥¼ ì°¾ê¸° ìœ„í•´ì„œëŠ” covaiance matrix(ê³µë¶„ì‚° í–‰ë ¬) ì˜ eigen vector(ê³ ìœ  ë²¡í„°) ê°’ì„ ì°¾ì•„ì•¼ í•˜ê³ , ì´ ê°’ ì¤‘ ê°€ì¥ í° ê°’ì´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” PC ì— ë§Œì¡±í•œë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. 

## 3. ë¶„ì‚°ì„ ìµœëŒ€ë¡œ ë³´ì¡´í•  ìˆ˜ ìˆëŠ” ì¶•ì„ ì„ íƒí•˜ëŠ” ì´ìœ ?
![](/assets/img/img_221121/pca_variance.png){: .center width="80%"} <br/>

ìœ„ì˜ ê·¸ë¦¼ì²˜ëŸ¼ ê°„ë‹¨í•œ 2ì°¨ì› ë°ì´í„°ì…‹ì´ ìˆì„ ë•Œ c2ì˜ ì§ì„ ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ë¶„ì‚°ì„ ê°€ì¥ ì ê²Œ ë‚˜íƒ€ë‚´ëŠ” ë°©ë²•ì¸ë°, ì´ë ‡ê²Œ ë˜ë©´ ë°ì´í„°ë¥¼ ìœ ì‹¤í•˜ê¸°ê°€ ì‰¬ì›Œì§„ë‹¤.

ë”°ë¼ì„œ, ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ íˆ¬ì˜í•˜ëŠ” ê²ƒ ë³´ë‹¤ ë¶„ì‚°ì„ ìµœëŒ€ë¡œ ë³´ì¡´í•  ìˆ˜ ìˆëŠ” ì¶•ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì •ë³´ë¥¼ ê°€ì¥ ì ê²Œ ì†ì‹¤í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤. ë¶„ì‚°ì´ ì»¤ì ¸ì•¼ ë°ì´í„°ë“¤ì‚¬ì´ì˜ ì°¨ì´ì ì´ ëª…í™•í•´ì§€ê³ , ê·¸ê²ƒì´ ëª¨ë¸ì„ ë”ìš± ì¢‹ì€ ë°©í–¥ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆì„ ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤.

## 4. PCA ì ìš©
#### Step 1 : ë°ì´í„° ì •ê·œí™” (ê° ë³€ìˆ˜ ê°’ë“¤ì˜ í‰ê·  = 0)
![](/assets/img/img_221121/pca_regularization.png){: .center width="80%"} <br/>

#### Step 2 : ìµœì í™” ë¬¸ì œ ì •ì˜
* ë°ì´í„°ë¥¼ ì‚¬ì˜ì‹œí‚¨ í›„ì˜ ë¶„ì‚°ì„ ìµœëŒ€í™”í•˜ëŠ” ìƒˆë¡œìš´ ì¶•ì„ ì°¾ëŠ” ê²ƒì´ ëª©í‘œ!

![](/assets/img/img_221121/max_variance.png){: .center width="60%"} <br/>

#### Step 3 : ìµœì í•´ ë„ì¶œ

![](/assets/img/img_221121/Lagrangian.png){: .center width="80%"} <br/>

* Lagrangian multiplierë¥¼ ì‚¬ìš©í•˜ì—¬ ì œì•½ì‹ì„ ëª©ì ì‹ì— ì¶”ê°€í•œ ìƒˆ ëª©ì ì‹ ìƒì„±
* ìƒˆ ëª©ì ì‹ì„ ë¯¸ë¶„í•˜ì—¬ ê¸°ìš¸ê¸°ê°€ 0ì´ ë˜ëŠ” ì ì—ì„œ ìµœì í•´ ë°œìƒ

#### Step 4 : ê³ ìœ ë²¡í„° (eigenvector) ë“¤ì„ ê³ ìœ ê°’ (eigenvalue) ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
* ê° ê³ ìœ ë²¡í„°ëŠ” ì„ í˜•ë³€í™˜ëœ ê³µê°„ì—ì„œ ì„œë¡œ ì§êµí•˜ëŠ” ìƒˆë¡œìš´ ì¶•ì´ ë¨

#### Step 5 : ë³€ìˆ˜ ì¶”ì¶œì„ í†µí•œ ë°ì´í„° ë³€í™˜

![](/assets/img/img_221121/extracted_data.png){: .center width="80%"} <br/>


#### Step 6 : ì¶”ì¶œëœ ë³€ìˆ˜ ì¤‘ ì¼ë¶€ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì—­ë³€í™˜

<br/>

![](/assets/img/img_221121/inverse_transform.png){: .center width="80%"} <br/>

## 5. ê²°ê³¼ í™•ì¸

â¡ï¸ **Scree Plot** 

![](/assets/img/img_221121/elbow_point.png){: .center width="50%"} <br/>

ìœ„ì˜ ê·¸ë˜í”„ì—ì„œ ë„¤ëª¨ì¹œ ê³³ì²˜ëŸ¼ ì •ë³´ì˜ ê°ì†ŒëŸ‰ì´ í™• ì¤„ì–´ë“œëŠ” êµ¬ê°„ì„ Elbow pointë¼ê³  ë¶€ë¥¸ë‹¤. Eigenvalueì˜ Elbowpointë¥¼ í™•ì¸í•˜ê³  ì ì ˆí•˜ê²Œ ëª‡ ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí• ì§€ ê²°ì •í•œë‹¤.

<br/>

â¡ï¸ **Loading Plot**

![](/assets/img/img_221121/loading_plot.png){: .center width="50%"} <br/>

í•´ë‹¹ plotì€ ê° ì£¼ì„±ë¶„ì„ ë§Œë“¤ ë•Œ, ê¸°ì¡´ ë°ì´í„° xì˜ ê° ë³€ìˆ˜ê°€ ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ íŒë‹¨í•˜ì—¬ ì‚¬í›„ì ì¸ ë³€ìˆ˜ì— ëŒ€í•œ í•´ì„ì„ í•  ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. 

<br/>

*** 

## ğŸ’» ì‹¤ìŠµ ì˜ˆì œ ì½”ë“œ 
```python
import seaborn as sns
import pandas as pd
from sklearn.decomposition import PCA

url = "https://archive.ics.uci.edu/ml/machine-learning-datebase/iris/irs.data"
df = pd.read_csv(url, 
                 naems = ['sepal length', 'sepal width', 'petal length',
                          'petal width', 'target'])
```

![](/assets/img/img_221121/df_iris.png){: .center width="60%"} <br/>


```python
# Use only continuous data
data = df[df.columns[0:4]]

# Create PCA object with number of principal component
pca = PCA(n_components = len(df.columns) - 1)
pca_fit = pca.fit(data)
```

```python
print('\n====== PCA Reulst Summary ======\n')
print('Singular value : \n', pca.singular_values_)
print('\n Singular vector : \n', pca.components_.T)
print('\n Explain Standard deviations : \n', np.sqrt(pca.explained_variance_))
print('\n Explain Variance Ratio : \n', pca.explained_variance_ratio_)
print('\n Noise Variance : \n', pca.noise_variance_)
```

```
====== PCA Reulst Summary ======

Singular value : 
 [25.08986398  6.00785254  3.42053538  1.87850234]

 Singular vector : 
 [[ 0.36158968  0.65653988 -0.58099728  0.31725455]
 [-0.08226889  0.72971237  0.59641809 -0.32409435]
 [ 0.85657211 -0.1757674   0.07252408 -0.47971899]
 [ 0.35884393 -0.07470647  0.54906091  0.75112056]]

 Explain Standard deviations : 
 [2.05544175 0.49218246 0.28022118 0.15389291]

 Explain Variance Ratio : 
 [0.92461621 0.05301557 0.01718514 0.00518309]

 Noise Variance : 
 0.0
 ```

```python
# Scree Plot
plt.title("Scree Plot")
plt.xlabel("Number of Components")
plt.ylabel("Cumulative Explained Variance")
plt.plot(pca.explained_variance_, 'o-')
```

![](/assets/img/img_221121/scree_plot.png){: .center width="60%"} <br/>


```python
# get predict values
pca_pred = pd.DataFrame(pca.fit_transform(data))
pca_pred = pd.concat([pca_pred, df['target']], axis = 1)
pca_pred
```

![](/assets/img/img_221121/pca_pred.png){: .center width="60%"} <br/>


```python
sns.scatterplot(pca_pred[0], pca_pred[1], data = pca_pred, hue = 'target',
                style = 'target', s = 100);
```

![](/assets/img/img_221121/scatterplot_pca.png){: .center width="60%"} <br/>



## ë§ˆë¬´ë¦¬í•˜ë©´ì„œ..
ì§€ë„í•™ìŠµë§Œ ì£¼ë¡œ ë‹¤ë£¨ë‹¤ ë³´ë‹ˆ PCAëŠ” ê°œë…ë§Œ ì•Œê³  ìˆê³  ì§ì ‘ í•´ë³¼ ê¸°íšŒê°€ ì—†ì—ˆëŠ”ë° ì´ë²ˆì— í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•´ ì •ë¦¬í•˜ë©´ì„œ ìš°ì—°íˆ ì°¨ì› ì¶•ì†Œ ì‹¤ìŠµ ì½”ë“œë¥¼ ë°œê²¬í–ˆë‹¤. ì§ì ‘ í•´ë³´ë‹ˆ ê°„ë‹¨í•˜ê³  ë” ì§ê´€ì ìœ¼ë¡œ í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•´ ì´í•´í•  ìˆ˜ ìˆì—ˆë‹¤. ë¹„ì§€ë„í•™ìŠµì„ ë‹¤ë£¨ê²Œ ë˜ëŠ” ê·¸ ì–´ëŠ ë‚  ì˜¤ëŠ˜ ê³µë¶€í•œ ë‚´ìš©ì´ ë„ì›€ì´ ë˜ê¸¸!!

### ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ ë§Œë‚˜ìš” ğŸ™Œ
<!-- ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” [K-MOOC ì‹¤ìŠµìœ¼ë¡œ ë°°ìš°ëŠ” ë¨¸ì‹ ëŸ¬ë‹](http://www.kmooc.kr/courses/course-v1:SSUk+SSMOOC20K+2022_T1/course/)ì—ì„œ ë‚´ê°€ ë¶€ì¡±í•œ ë¶€ë¶„ë“¤ì„ ì •ë¦¬í•´ ë” ì‘ì„±í•  ì˜ˆì •ì´ë‹¤. -->

<br/>

***

## ì°¸ê³ 


[K-MOOC ì‹¤ìŠµìœ¼ë¡œ ë°°ìš°ëŠ” ë¨¸ì‹ ëŸ¬ë‹](http://www.kmooc.kr/courses/course-v1:SSUk+SSMOOC20K+2022_T1/course/)

[ë¨¸ì‹ ëŸ¬ë‹ - PCA (Principal Component Analysis)](https://velog.io/@swan9405/PCA)

[Stack Exchange - Making sense of principal component analysis, eigenvectors & eigenvalues](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)

[[sklearn] PCA (Principal Component Analysis)](https://m.blog.naver.com/pjc1349/221996214527)





<!-- ### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾ 
<font color='dodgerblue'> ì˜ˆìœ íŒŒë‘ </font>
<font color='lightgray'>Miss</font>
<mark style='background-color: #f1f8ff'> ì—°í•œ íŒŒë‘ </mark>
<mark style='background-color: #fff5b1'> ì—°í•œ ë…¸ë‘ </mark>
<mark style='background-color: #ffdce0'> ì—°í•œ ë¹¨ê°• </mark>
<mark style='background-color: #dcffe4'> ì—°í•œ ì´ˆë¡ </mark>
<mark style='background-color: #f5f0ff'> ì—°í•œ ë³´ë¼ </mark>
<mark style='background-color: #f6f8fa'> ì—°í•œ íšŒìƒ‰ </mark>
-->
