---
layout: post
title:  "Tips | Ensemble Model Comparison"
date:   2022-11-17 16:00:09 +0900
categories: Tips
style: border
color: danger
description: sklearn íŠ¸ë¦¬ ì•™ìƒë¸” ëª¨ë¸ 4ê°€ì§€
tags: [sklearn, Tree, Ensemble]
---
# [ ML ] sklearn íŠ¸ë¦¬ ì•™ìƒë¸” ëª¨ë¸ 4ê°€ì§€



## ì•™ìƒë¸” <font color = 'lightgray'>Ensemble</font>
ì•™ìƒë¸”ì´ë€ 
ì—¬ëŸ¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ ë” ê°•ë ¥í•œ ëª¨ë¸ì„ ë§Œë“œëŠ” ê¸°ë²•ìœ¼ë¡œ, í•´ë‹¹ í¬ìŠ¤íŠ¸ëŠ” ê·¸ ì¤‘ì—ì„œë„

**1. RandomForest** <br/>
**2. ExtraTree** <br/>
**3. GradientBoosting** <br/> 
**4. Histogram-based-Gradient-Boosting** <br/>
 
ì´ë ‡ê²Œ ì´ 4ê°€ì§€ì˜ íŠ¸ë¦¬ ì•™ìƒë¸” ëª¨ë¸ì„ ê³µë¶€í•˜ê³  ì •ë¦¬í•˜ì˜€ë‹¤.



### 1. ëœë¤ í¬ë ˆìŠ¤íŠ¸ <font color = 'lightgray'>RandomForest</font>

![](/assets/img/img_221117/random_forest_img.png){: .center width="70%"}

ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” ì§€ë„ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, Treeê°€ ëª¨ì—¬ Forestë¥¼ ì´ë£¬ë‹¤ê³  í•´ì„œ Forestë¼ëŠ” ì´ë¦„ì´ ë¶™ì—ˆë‹¤. ì—¬ê¸°ì„œ TreeëŠ” ê²°ì • íŠ¸ë¦¬ (Decision Tree)ë¥¼ ë§í•œë‹¤. Train dataì— overfittingë  ìˆ˜ ìˆëŠ” ê²°ì • íŠ¸ë¦¬ì˜ ë‹¨ì ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬ë¥¼ í†µí•´ ì˜ˆì¸¡í•˜ì—¬ overfittingì„ ì¤„ì¸ë‹¤.

```python
# RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
RandomForestClassifier(n_estimators=100, criterion="gini", max_depth=None,
                      min_samples_split = 2, min_samples_leaf = 1, min_weight_fraction_leaf = 0.0,
                      max_featrues = "sqrt", max_leaf_nodes = None, min_impurity_decrease = 0.0,
                      boostrap = True, oob_score = False, n_jobs = None, random_state = None,
                      verbose = 0, warm_start = False, class_weight = None, ccp_alpha = 0.0, max_samples = None)
```

```python
# RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor
RandomForestRegressor(n_estimators = 100, criterion = "squared_error", max_depth = None,
                      min_samples_split = 2, min_samples_leaf = 1, min_weight_fraction_leaf = 0.0,
                      max_featrues = 1.0, max_leaf_nodes = None, min_impurity_decrease = 0.0,
                      boostrap = True, oob_score = False, n_jobs = None, random_state = None,
                      verbose = 0, warm_start = False, ccp_alpha = 0.0, max_samples = None)
```


### 2. ì—‘ìŠ¤íŠ¸ë¼ íŠ¸ë¦¬ <font color = 'lightgray'>ExtraTree</font>
![](/assets/img/img_221116/extra_tree_model.png){: .center width="50%"}

ëœë¤ í¬ë ˆìŠ¤íŠ¸ì™€ ì „ì²´ì ì¸ ì›ë¦¬ëŠ” ë¹„ìŠ·í•˜ë‹¤.

**ğŸ¤” ê·¸ë ‡ë‹¤ë©´ ì–´ë–¤ ì ì´ ë‹¤ë¥¼ê¹Œ?**

* Bootstrap ì´ìš© ì—¬ë¶€
  * Random ForestëŠ” bootstrap samplingì„ ì‚¬ìš©í•˜ì§€ë§Œ
  * Extra TreeëŠ” ì´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì „ì²´ train datasetì„ ì‚¬ìš©í•¨


* íŠ¸ë¦¬ ë¶„í•  ì‹œ ë³€ìˆ˜ ì„ íƒ ê³¼ì •
  * Random ForestëŠ” ê°ê°ì˜ íŠ¸ë¦¬ì—ì„œ, boostrap samplingëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ëœë¤í•œ features**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§Œë“¤ ìˆ˜ ìˆëŠ” **ìµœì ì˜ íŠ¸ë¦¬**ë¥¼ ìƒì„±
  * Extra TreeëŠ” ê°ê°ì˜ íŠ¸ë¦¬ì—ì„œ, **original data**ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëœë¤í•œ feature ì‚¬ìš©í•˜ì§€ë§Œ, ìµœì ì˜ íŠ¸ë¦¬ë¥¼ ë§Œë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼ **ê°ê° split ì§€ì **ì—ì„œ **ë¬´ì‘ìœ„ì˜ feature**ë¥¼ ì„ íƒí•˜ì—¬ ê·¸ featureì— ëŒ€í•œ **ìµœì ì˜ partition**ì„ ì°¾ì•„ **split**ì„ ì§„í–‰í•œë‹¤. 

**âœ… Random Forestì— ë¹„í•´ Extra TreeëŠ”**

1. ì—°ì‚°ëŸ‰ì´ ì ë‹¤.
2. ëœë¤ì„±ì´ ì¦ê°€í•˜ë©´ì„œ ëª¨ë¸ì˜ biasëŠ” ì¦ê°€
3. ê·¸ëŸ¬ë‚˜ Random Forestë³´ë‹¤ ëœë¤ì„±ì´ ì¡°ê¸ˆ ë” í¬ê¸° ë•Œë¬¸ì— ë” ë§ì€ ê²°ì •íŠ¸ë¦¬ë¥¼ í•™ìŠµí•´ì•¼í•¨ <br/>  â¡ï¸ ì¼ë°˜ì ìœ¼ë¡œ Random Forestê°€ ë” ì„ í˜¸ëœë‹¤.

```python
# ExtraTreesClassifier
from sklearn.ensemble import ExtraTreesClassifier
ExtraTreesClassifier(n_estimators=100, *, criterion='gini', max_depth=None, 
                     min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, 
                     max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, 
                     bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0, 
                     warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)
```

```python
# ExtraTreesRegressor
from sklearn.ensemble import ExtraTreesRegressor
ExtraTreesRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, 
                    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, 
                    max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False,
                    oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, 
                    ccp_alpha=0.0, max_samples=None)
```

### 3. ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… <font color='lightgray'>Gradient Boosting</font>
![](/assets/img/img_221116/gradient_boosting.png){: .center}

**Gradient Boosting**ì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ì–•ì€ íŠ¸ë¦¬ì™€ ê°„ë‹¨í•œ ëª¨ë¸ (ì•½í•œ í•™ìŠµê¸°)ë¥¼ ë§ì´ ì—°ê²°í•˜ëŠ” ê²ƒì´ë‹¤. Random Forestì™€ ë‹¬ë¦¬ ëœë¤ì„±ì´ ìˆëŠ” ê²Œ ì•„ë‹ˆë¼ **ì´ì „ íŠ¸ë¦¬ì˜ ì˜¤ì°¨ë¥¼ ë³´ì™„**í•˜ëŠ” ë°©ì‹ì„ ì´ìš©í•´ ìˆœì°¨ì ìœ¼ë¡œ íŠ¸ë¦¬ë¥¼ ë§Œë“ ë‹¤. Random Forestë³´ë‹¤ëŠ” ë§¤ê°œë³€ìˆ˜ ì„¤ì •ì— ì¢€ ë” ë¯¼ê°í•˜ì§€ë§Œ, ì˜ ì¡°ì •í•˜ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.

ê° íŠ¸ë¦¬ì˜ ê¹Šì´ê°€ ì–•ì•„ì„œ overfittingì„ í”¼í•˜ê¸°ì— ì•„ì£¼ ì¢‹ë‹¤. 

```python
# GradientBoostingClassifier
from sklearn.ensemble import GradientBoostingClassifier
GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, 
                           subsample=1.0, criterion='friedman_mse', min_samples_split=2,
                           min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, 
                           min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, 
                           verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, 
                           n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)
```

```python
# GradientBoostingRegressor
from sklearn.ensemble import GradientBoostingRegressor
GradientBoostingRegressor(*, loss='squared_error', learning_rate=0.1, n_estimators=100, 
                          subsample=1.0, criterion='friedman_mse', min_samples_split=2, 
                          min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, 
                          min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, 
                          alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, 
                          validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)
```

### 4. íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ… <font color='lightgray'>Histogram-based-Gradient-Boosting</font>

sklearnì˜ **íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…**ì€ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ì˜ LightGBMì— ì˜í–¥ì„ ë°›ì•˜ê³ , ì´ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” sklearn ì´ì™¸ì—ë„ ì—¬ëŸ¬ ê°œê°€ ìˆë‹¤.

ì…ë ¥ íŠ¹ì„±ì„ 256ê°œì˜ ì •ìˆ˜ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ë©°, ê·¸ ì¤‘ í•˜ë‚˜ëŠ” ëˆ„ë½ëœ ê°’ì„ ìœ„í•´ ì‚¬ìš©í•œë‹¤.

ì…ë ¥ì— ëˆ„ë½ëœ íŠ¹ì„±ì´ ìˆë”ë¼ë„ ì „ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•Šì•„ë„ ë˜ë©°, ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ë¶€ìŠ¤íŒ… ëª¨ë¸ì— ë¹„í•´ ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜ì—ì„œ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ë˜í•œ, ëŒ€ìš©ëŸ‰ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£° ë•Œ Gradient Boostingë³´ë‹¤ ë¹ ë¥´ê²Œ ì‘ë™í•œë‹¤. overfittingì„ ì˜ ì–µì œí•˜ë©´ì„œ Gradient Boostingë³´ë‹¤ëŠ” ì¢€ ë” ë†’ì€ ì„±ëŠ¥ì„ ì œê³µí•œë‹¤ê³  í•œë‹¤. 

```python
# HistGradientBoostingClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
HistGradientBoostingClassifier(loss='log_loss', *, learning_rate=0.1, 
                               max_iter=100, max_leaf_nodes=31, 
                               max_depth=None, min_samples_leaf=20, 
                               l2_regularization=0.0, max_bins=255,
                               categorical_features=None, monotonic_cst=None,
                               warm_start=False, early_stopping='auto', 
                               scoring='loss', validation_fraction=0.1,
                               n_iter_no_change=10, tol=1e-07, 
                               verbose=0, random_state=None)
```


Feature Importanceë¥¼ êµ¬í•˜ëŠ” í•¨ìˆ˜ê°€ ë”°ë¡œ ì—†ê¸° ë•Œë¬¸ì— ë‹¤ìŒ ì½”ë“œë¥¼ ì´ìš©í•˜ë©´ ëœë‹¤.

```python
from sklearn.inspection import permutation_importance
sklearn.inspection.permutation_importance(estimator, X, y, *, 
																					scoring=None, n_repeats=5, 
																					n_jobs=None, 
																					random_state=None, 
																					sample_weight=None, 
																					max_samples=1.0)
```



### ì°¸ê³ 
[ë¨¸ì‹ ëŸ¬ë‹ | íŠ¸ë¦¬ì˜ ì•™ìƒë¸” | sklearn ì•™ìƒë¸” ëª¨ë¸ 4ì¢…ë¥˜ íŠ¹ì§• ë¹„êµ](https://splendidlolli.tistory.com/441)

[ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì•™ìƒë¸”-ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…](https://jhryu1208.github.io/data/2020/11/16/ML_decision_tree_ensemble_gradientboosting/)