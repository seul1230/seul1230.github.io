---
layout: post
title:  "2022_likelion TIL"
date:   2022-12-08 16:00:09 +0900
categories: Python_DataAnalysis
---
# [ 1208 ] Image Classification ì‹¤ìŠµ
#### ğŸ‘©ğŸ»â€ğŸ’» ì˜¤ëŠ˜ì½”ë“œ ì‹¤ì‹œê°„ ê°•ì˜ _ ë°•ì¡°ì€ë‹˜
í•´ë‹¹ í¬ìŠ¤íŠ¸ëŠ” [**TensorFlow - ì´ë¯¸ì§€ ë¶„ë¥˜**](https://www.tensorflow.org/tutorials/images/classification) íŠœí† ë¦¬ì–¼ì„ ì°¸ê³ í•´ CNN ë ˆì´ì–´ë¥¼ ìŒ“ì•„ë³´ì•˜ë‹¤.


<!-- ğŸ“™ ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” **ì´ë¡  ë° ê°œë…**ì„ ì¤‘ì‹¬ì ìœ¼ë¡œ ë‹¤ë£° ì˜ˆì •ì´ë‹¤. -->



<br/>

***


## ğŸ“™ ì´ë¡  ë° ê°œë… <br/>

### 1. í•©ì„±ê³± ì‹ ê²½ë§ <font color='lightgray'>CNN, Convolutional Neural Network</font> <br/>

#### [ <mark style='background-color: #fff5b1'>CNN ë“±ì¥ë°°ê²½</mark> ]
**ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  MLP**ëŠ” ì´ë¯¸ì§€ í”½ì…€ë§ˆë‹¤ **ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ ê°’**ì„ ë¶€ì—¬í•˜ë©°, í”½ì…€ ê°’ í•˜ë‚˜ë§Œ ë‹¬ë¼ì ¸ë„ ë‹¤ë¥´ê²Œ ê³„ì‚°ëœë‹¤. <br/>

![](/assets/img/img_221208/mlp_cnn.png){: .center width='70%'}


â¡ï¸ **CNN**ì„ í†µí•´ ê°ì²´ì˜ ìœ„ì¹˜ê°€ ë°”ë€Œì–´ë„ ê°™ì€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ë„ë¡ ê° ì˜ì—­ì˜ **ì¸ì ‘ ë°ì´í„°**ë¥¼ ì¡°ì‚¬í•´ íŠ¹ì§•ì„ íŒŒì•…í•˜ì !

#### [ <mark style='background-color: #fff5b1'>CNNì´ë€?</mark> ]
CNNì€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê¸° ìœ„í•´ íŒ¨í„´ì„ ì°¾ëŠ”ë° ìœ ìš©í•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ í•™ìŠµí•˜ê³  íŒ¨í„´ì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•œë‹¤. CNNì˜ í•µì‹¬ì ì¸ ê°œë…ì€ ì´ë¯¸ì§€ì˜ **ê³µê°„ì •ë³´ë¥¼ ìœ ì§€í•˜ë©° í•™ìŠµì„ í•œë‹¤**ëŠ” ê²ƒì´ë‹¤. CNNì€ **í•„í„°ë§ ê¸°ë²•**ì„ ì¸ê³µ ì‹ ê²½ë§ì— ì ìš©í•¨ìœ¼ë¡œì¨ ì´ë¯¸ì§€ë¥¼ ë”ìš± íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´  Yann LeCun ì´ ì œì•ˆí•˜ì˜€ìœ¼ë©° í˜„ì¬ ë”¥ ëŸ¬ë‹ì—ì„œ ì´ìš©ë˜ê³  ìˆëŠ” í˜•íƒœì˜ CNNì´ ì œì•ˆë˜ì—ˆë‹¤. `(image_height, image_width, color_channels)` ì˜ í…ì„œë¥¼ ì‚¬ìš©í•˜ë©°, ì´ë•Œ color_channels ëŠ” (**<font color='red'>R</font>**,**<font color='green'>G</font>**,**<font color='blue'>B</font>**)ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. TF APIëŠ” ë‹¤ìŒì˜ ë°©ë²•ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.

```python
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
```

![](/assets/img/img_221208/cnn_how.gif){: .center width='70%'}

**1ï¸âƒ£ Convolution ì—°ì‚°ì„ í•˜ë©´ í•„í„°ë¥¼ í†µê³¼ì‹œì¼œì„œ filters ê°œìˆ˜ë§Œí¼ í”¼ì²˜ë§µì„ ìƒì„±í•œë‹¤.**<br/><br/>
**2ï¸âƒ£ í”¼ì²˜ë§µ Outputì— Activation Function ì„ í†µê³¼ì‹œì¼œì„œ ì•¡í‹°ë² ì´ì…˜ì„ ìƒì„±í•œë‹¤.** <br/>
    => ReLU ë“±ì„ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ ì¶œë ¥ê°’ì— í™œì„±í™” í•¨ìˆ˜ë¥¼ ì ìš©í•œ ì•¡í‹°ë² ì´ì…˜ë§µì„ ë°˜í™˜í•œë‹¤. <br/><br/>
**3ï¸âƒ£ Pooling ì—ëŠ” Max, Average, Min ë“± ì—¬ëŸ¬ ë°©ë²•ì´ ìˆëŠ”ë°, ë³´í†µ MaxPooling ì„ ì£¼ë¡œ ì‚¬ìš©í•œë‹¤.** <br/>
    => í‘ë°±ì´ë¯¸ì§€ì—ì„œëŠ” MinPooling ì„ ì‚¬ìš©í•˜ê¸°ë„ í•œë‹¤.<br/><br/>
**4ï¸âƒ£ CNN ê´€ë ¨ ë…¼ë¬¸** 
* **VGG16**, **VGG19** : ì¸µì„ 16ê°œ, 19ê°œ ë§Œí¼ ê¹Šê²Œ ë§Œë“  ê²ƒì„ ì˜ë¯¸
* 30~50ì¸µê¹Œì§€ ìŒ“ê¸°ë„ í•˜ê³  100ì¸µ ì •ë„ ìŒ“ê¸°ë„ í•©ë‹ˆë‹¤. ì¸µì˜ ìˆ˜ë¥¼ ëª¨ë¸ì˜ ì´ë¦„ì— ë¶™ì´ê¸°ë„ í•©ë‹ˆë‹¤. <br/>
    => ê³¼ê±°ì— ë¹„í•´ GPU ë“±ì˜ ì—°ì‚°ì„ ë” ë§ì´ ì§€ì›í•˜ê¸° ë•Œë¬¸ì— ì—°ì‚°ì´ ë¹¨ë¼ì§„ ë•ë¶„ì´ê¸°ë„ í•©ë‹ˆë‹¤. <br/>

**5ï¸âƒ£ Padding, Stride** <br/>
* **Padding**, **Stride** : ì…ë ¥ê³¼ ì¶œë ¥ì‚¬ì´ì¦ˆë¥¼ ì¡°ì •
* StrideëŠ” í•„í„°ì˜ ì´ë™ ë³´í­ì„ ì¡°ì •í•˜ê¸°ë„ í•¨

<br/>

**ğŸš€ CNN ì‘ë™ì›ë¦¬ ë³´ëŸ¬ê°€ê¸°** <br/>
CNN Explainer : <https://poloclub.github.io/cnn-explainer/>

![](/assets/img/img_221208/cnn_how.png){: .center width='70%'}




### 2. Pooling
* í•©ì„±ê³±ì¸µì—ì„œ ë°›ì€ ìµœì¢… **Activation Map** (ì¶œë ¥ ë°ì´í„°) ì˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ íŠ¹ì • ë°ì´í„° ê°•ì¡°
* ë°ì´í„° ì‚¬ì´ì¦ˆ ì¤„ì—¬ì£¼ë©° ë…¸ì´ì¦ˆ ìƒì‡„ì‹œí‚¤ê³ , ë¯¸ì„¸í•œ ë¶€ë¶„ì—ì„œ ì¼ê´€ì ì¸ íŠ¹ì§• ì œê³µ
* Max pooling / Average Pooling / Min Pooling
* **<mark style='background-color: #fff5b1'>Poolingì„ í•´ì£¼ëŠ” ì´ìœ </mark>**
    * íŒŒë¼ë¯¸í„°ë¥¼ ì¤„ì—¬ì„œ ì´ë¯¸ì§€ ì¶”ìƒí™” -> **overfitting** ë°©ì§€
    * íŒŒë¼ë¯¸í„°ê°€ ì¤„ì–´ì„œ ê³„ì‚°ì´ ê°ì†Œ, í•˜ë“œì›¨ì–´ì— ìˆëŠ” ë¦¬ì†ŒìŠ¤ê°€ ì ˆì•½ë¨
    * ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ **ê³„ì‚°ì„ íš¨ìœ¨**ì ìœ¼ë¡œ í•˜ê³  **ë°ì´í„°ë¥¼ ì••ì¶•**í•˜ëŠ” íš¨ê³¼
    * **ì†ë„ ì¦ê°€**
* ëŒ€ì²´ì ìœ¼ë¡œ ì»¬ëŸ¬ì´ë¯¸ì§€ì—ì„œëŠ” MaxPooling ì„ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” í¸ì´ë‹¤.
* í‘ë°±ì´ë¯¸ì§€ì—ì„œëŠ” MinPooling ì„ ì‚¬ìš©í•˜ê¸°ë„ í•œë‹¤.


### 3. Padding

![](/assets/img/img_221208/padding.png){: .center width='70%'}

* valid
    * ìœ íš¨í•œ ì˜ì—­ë§Œ ì¶œë ¥ì´ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì¶œë ¥ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆëŠ” ì…ë ¥ ì‚¬ì´ì¦ˆë³´ë‹¤ ì‘ìŒ
* same
    * ì¶œë ¥ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ ì…ë ¥ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì™€ ë™ì¼


* [**CNN Explainer**](https://poloclub.github.io/cnn-explainer/)ì— ë“¤ì–´ê°€ë©´ CNNì˜ ì›ë¦¬ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ê³  Hyperparameterë¥¼ ë°”ê¿”ì£¼ì—ˆì„ ë•Œ í•„í„°ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ë³¼ ìˆ˜ ìˆë‹¤.

![](/assets/img/img_221208/understanding_hyperparameter.png){: .center width='60%'}


### 4. Image Overfitting ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” ê²½ìš°
* ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    * ì¤‘ì ì ì¸ ì´ìœ  - ë…¸ì´ì¦ˆ ë°ì´í„°ê°€ ë§ë‹¤
* í›ˆë ¨ ì˜ˆì œê°€ ì ì„ ë•Œ
    * ëª¨ë¸ì€ ìƒˆë¡œìš´ ì˜ˆì œì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì •ë„ê¹Œì§€ í›ˆë ¨ ì˜ˆì œì˜ ë…¸ì´ì¦ˆë‚˜ ì›ì¹˜ ì•ŠëŠ” ì„¸ë¶€ê¹Œì§€ í•™ìŠµí•¨
    * ë°ì´í„° ì¦ê°•, ë“œë¡­ì•„ì›ƒ ì¶”ê°€ ë“±

### 5. ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ëŠ” ë°©ë²•
1ï¸âƒ£ **matplotlib.pyplot**ì˜ **imread()**ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²• <br/>
2ï¸âƒ£ **PIL** <font color='lightgray'>Pillow</font> ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²• <br/>
&nbsp; => PIL ë¡œ **ì ‘ê³ ëŒë¦¬ê³ ë•¡ê¸°ê³ **ê°€ ë‹¤ ê°€ëŠ¥. <br/>
&nbsp; => TF ë‚´ë¶€ì—ì„œë„ PIL ì´ë‚˜ OpenCVë¥¼ ì‚¬ìš©í•´ì„œ **ì ‘ê³ ëŒë¦¬ê³ ë•¡ê¸°ê³ ** <br/>
&nbsp; => ì´ë¯¸ì§€ í¸ì§‘ê¸°ë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆìŒ.<br/>
3ï¸âƒ£ **OpenCV**ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²• : Computer Vision ì— ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ë¡œ ë™ì˜ìƒì²˜ë¦¬ ë“±ì— ì£¼ë¡œ ì‚¬ìš©

### 6. kerasì˜ ImageDataGenerator 
* ê³µê°„ ë ˆë²¨ ë³€í˜•
    * Flip : ìƒí•˜, ì¢Œìš° ë°˜ì „
    * Rotation : íšŒì „
    * Shift : ì´ë™
    * Zoom : í™•ëŒ€, ì¶•ì†Œ
    * Shear : ëˆ•íˆê¸°
* í”½ì…€ ë ˆë²¨ ë³€í˜•
    * Bright : ë°ê¸° ì¡°ì •
    * Channel Shift : RGB ê°’ ë³€ê²½
    * ZCA Whitening : Whitening íš¨ê³¼





<br/>

***

## ğŸ’» ì‹¤ìŠµ ì˜ˆì œ ì½”ë“œ
### : CNN tutorial

**ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°** - CIFAR10 ë°ì´í„°ì„¸íŠ¸
```python
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
```

**ë°ì´í„° í™•ì¸**

```python
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i])
    # The CIFAR labels happen to be arrays, 
    # which is why you need the extra index
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()
```
![](/assets/img/img_221208/CIFAR.png){: .center width='30%'} 


**í•©ì„±ê³± ì¸µ ë§Œë“¤ê¸°**

```python
model = models.Sequential()
model.add(layers.Conv2D(filters = 32, kernel_size = (3, 3), 
                        activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation='relu'))
```

## ğŸ’» ì‹¤ìŠµ ì˜ˆì œ ì½”ë“œ
### : Image Classification
í•´ë‹¹ íŠœí† ë¦¬ì–¼ì€ ê½ƒ 5ê°€ì§€ ì´ë¯¸ì§€ë¥¼ í•™ìŠµí•˜ê³  ë¶„ë¥˜í•˜ëŠ” ì˜ˆì œì´ë‹¤. ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'] 5ê°€ì§€ ê½ƒì„ ë¶„ë¥˜í•œë‹¤.

**[ ì´ë¯¸ì§€ í™•ì¸ ]**
```python
roses = list(data_dir.glob('roses/*'))
PIL.Image.open(str(roses[0]))
```
![](/assets/img/img_221208/rose_0.png){: .center width='30%'} 


**[ ë°ì´í„° ì‹œê°í™”í•˜ê¸° ]**
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")
```
![](/assets/img/img_221208/flowers.png){: .center width='50%'} 

<br/>


**[ ì„±ëŠ¥ì„ ë†’ì´ë„ë¡ ë°ì´í„°ì…‹ êµ¬ì„±í•˜ê¸° ]** <br/>
ë²„í¼ë§ëœ prefetchë¥¼ ì‚¬ìš©í•˜ì—¬ I/Oë¥¼ ì°¨ë‹¨í•˜ì§€ ì•Šê³  ë””ìŠ¤í¬ì—ì„œ ë°ì´í„° ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ê² ë‹¤. prefetchëŠ” í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ë°ì´í„° ì „ì²˜ë¦¬ ë° ëª¨ë¸ ì‹¤í–‰ì„ ì¤‘ì²©ì‹œí‚¨ë‹¤.
```python
AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
```

**[ ë°ì´í„° ì¦ê°• ]**
```python
data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(img_height,
                                  img_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)
```

**[ ëª¨ë¸ ë§Œë“¤ê¸° ]**
```python
num_classes = len(class_names)

model = Sequential([
  data_augmentation,
  layers.Rescaling(1./255),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Dropout(0.2),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes, name="outputs")
])
```

### ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ ë§Œë‚˜ìš” ğŸ™Œ


<br/>

***
## ì°¸ê³ 
**ğŸ¤” Multi class ì˜ˆì¸¡ê°’ì´ ë‚˜ì™”ì„ ë•Œ ê°€ì¥ í° indexë¥¼ ë°˜í™˜í•˜ëŠ” Numpy ë©”ì†Œë“œ?** <br/>
np.argmax() ë¥¼ í†µí•´ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜ë°›ì•„ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ë‹µìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.

**ğŸ¤” softmaxì™€ sigmoid**<br/>
softmax ëŠ” nê°œì˜ í™•ë¥ ê°’ì„ ë°˜í™˜í•˜ê³  ì „ì²´ì˜ í•©ì€ 1ì´ ëœë‹¤. 2ê°œ ì¤‘ì— í•˜ë‚˜ë¥¼ ì˜ˆì¸¡í•  ë•ŒëŠ” softmax ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆê¸°ëŠ” í•˜ì§€ë§Œ ë³´í†µ sigmoid ë¥¼ ì‚¬ìš©í•œë‹¤.

**ğŸ¤” roundì™€ intì˜ ì°¨ì´?**<br/>
ì„ê³„ê°’ì„ ì •í•˜ê³  í¬ê³ ì‘ë‹¤ë¡œ íŒë‹¨ì„ í•´ì•¼í•˜ëŠ”ë° astype(int) ëŠ” ë§ˆì§€ë§‰ì— ì†Œìˆ«ì ì„ ìë¥´ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ê³  ìš°ì„  ì„ê³„ê°’ë³´ë‹¤ í°ì§€ ì‘ì€ì§€ íŒë‹¨í•˜ëŠ” ê³¼ì •ì´ ëˆ„ë½ë˜ì—ˆë‹¤.

**ğŸ¤” ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¥¼ í†µê³¼í•œ ê²°ê³¼ 10ê°œì˜ í”¼ì²˜ë¥¼ ë¬´ì—‡ì´ë¼ê³  ë¶€ë¥¼ê¹Œìš”?**<br/>
Feature map

**ğŸ¤” í”¼ì²˜ë§µì´ relu í™œì„±í™” í•¨ìˆ˜ë¥¼ í†µê³¼í•œ ê²ƒì„ ë¬´ì—‡ì´ë¼ê³  ë¶€ë¥¼ê¹Œìš”?**<br/>
Activation Map

**ğŸ¤” DNNì„ ì´ë¯¸ì§€ ë°ì´í„°ì— ì‚¬ìš©í–ˆì„ ë•Œ ì–´ë–¤ ë‹¨ì ì´ ìˆì„ê¹Œìš”?**<br/>
ì¸ì ‘ê³µê°„ì— ëŒ€í•œ ì •ë³´ë¥¼ ìœ ì‹¤í•˜ê²Œ ëœë‹¤. Flattenì„ í†µí•´ 1ì°¨ì› ë²¡í„° í˜•íƒœë¡œ ì£¼ì…ì„ í•´ì•¼í•˜ê¸° ë•Œë¬¸ì´ë‹¤.<br/>
1) flatten() ìœ¼ë¡œ 1ì°¨ì› ë²¡í„° í˜•íƒœë¡œ ì£¼ì…ì„ í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì¸ì ‘ ê³µê°„ì— ëŒ€í•œ ì •ë³´ë¥¼ ìƒì–´ë²„ë¦¬ê²Œ ë©ë‹ˆë‹¤. <br/>
2) 1ì°¨ì› í˜•íƒœë¡œ ì£¼ì…ì„ í•´ì£¼ê²Œ ë˜ë©´ ì…ë ¥ê°’ì´ ì»¤ì„œ ê³„ì‚°ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. <br/>
3) Convê³¼ Pooling ì—°ì‚°ì„ í•˜ê²Œ ë˜ë©´ ë°ì´í„°ì˜ ê³µê°„ì ì¸ íŠ¹ì§•ì„ í•™ìŠµí•˜ì—¬ ì–´ë–¤ íŒ¨í„´ì´ ìˆëŠ”ì§€ë¥¼ ì•Œê²Œ ë˜ë©° <br/>
4) Pooling ì„ í†µí•´ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ë©´ ë°ì´í„°ì˜ ìš©ëŸ‰ì´ ì¤„ì–´ë“¤ë©°, ì¶”ìƒí™”ë¥¼ í•˜ê¸° ë•Œë¬¸ì— ë„ˆë¬´ ìì„¸íˆ í•™ìŠµí•˜ì§€ ì•Šê²Œ ë©ë‹ˆë‹¤. ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•´ ì¤ë‹ˆë‹¤.

### ìë£Œ

[CNN (Convolutional Neural Network) ê°œë…](https://sungwookkang.com/1408)

[TensorFlow - ì´ë¯¸ì§€ ë¶„ë¥˜](https://www.tensorflow.org/tutorials/images/classification)


<!-- ### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾
### ğŸ¾ã€€ã€€ğŸ¾ 
<font color='dodgerblue'> ì˜ˆìœ íŒŒë‘ </font>
<font color='lightgray'>Miss</font>
<mark style='background-color: #f1f8ff'> ì—°í•œ íŒŒë‘ </mark>
<mark style='background-color: #fff5b1'> ì—°í•œ ë…¸ë‘ </mark>
<mark style='background-color: #ffdce0'> ì—°í•œ ë¹¨ê°• </mark>
<mark style='background-color: #dcffe4'> ì—°í•œ ì´ˆë¡ </mark>
<mark style='background-color: #f5f0ff'> ì—°í•œ ë³´ë¼ </mark>
<mark style='background-color: #f6f8fa'> ì—°í•œ íšŒìƒ‰ </mark>
-->
